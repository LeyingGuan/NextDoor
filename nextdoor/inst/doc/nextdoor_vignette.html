<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Leying Guan and Rob Tibshirani</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h3>Leying Guan and Rob Tibshirani</h3>

<h4>Yale October 1, 2019</h4>

<p>Introduction and installation</p>

<blockquote>
<p><a href="#intro">Introduction</a></p>

<p><a href="#install">Installation</a></p>
</blockquote>

<p>Nextdoor analysis for generalized liner regression with lasso penalty</p>

<blockquote>
<p><a href="#glmnet">nextdoor.glmnet</a></p>
</blockquote>

<p>Nextdoor analysis for general supervised learning algorithms</p>

<blockquote>
<p><a href="#supervised1">nextdoor</a></p>

<p><a href="#supervised2">getIndex</a></p>
</blockquote>

<p><a id="intro"></a></p>

<h2>Introduction</h2>

<p>Nextdoor is a package that performs feature indispensability test after model selection. For any feature \(j\) and any pre-fixed training procedure \(\mathcal{M}\), it access the indispensability of feature \(j\) by considering whether excluding \(j\) will lead to deterioration in the out-of-sample prediction power if we use the training procedure \(\mathcal{M}\). Formally speaking, we are interested in the following hypothesis testing problem:</p>

<p>\[
H_0: Err(j, \mathcal{M}) \leq Err(\mathcal{M}) \quad vs. \quad H_1: Err(j,\mathcal{M}) > Err(\mathcal{M}).
\]</p>

<p>Here Err(j,\(\mathcal{M}\)) is the out-of-sample test error if we apply the training procedure \(\mathcal{M}\) to our data set without feature \(j\) and Err(\(\mathcal{M}\)) is the out-of-sample test error if we apply the training procedure \(\mathcal{M}\) to our data set with all features.</p>

<p>As an example, we consider a linear regression problem with lasso penalty.</p>

<p>\[
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} (y_i-\beta_0-\beta^T x_i)^2 + \lambda ||\beta||_1,
\]
The training procedure \(\mathcal{M}\) is to apply the model above to our data set. For any feature \(j\), the same procedure without it is to consider the model
\[
\min_{\beta_0,\beta:\beta_j = 0} \frac{1}{N} \sum_{i=1}^{N} (y_i-\beta_0-\beta^T x_i)^2 + \lambda ||\beta||_1,
\]
We can use cross-validation to as an proxy to the out-of-sample test errors.</p>

<p>In practice, both the penalty value \(\lambda\) and the feature \(j\) to look at are data adaptive. For examples, we may pick the \(\lambda\) that achieves the smallest cross-validation error, and we may choose to look at the feature \(j\) that is in the original selected model.</p>

<p>Next-door analysis taken into account the selection bias and randomness in the above selections by</p>

<pre><code> 1. Debiasing the selected cross-validation error estimates.
 2. Taking into consideration  the probability of any feature being selected.
</code></pre>

<p>By the end, the Next-door analysis tries to answer a non-random question of whether we can reject \(H_0\) or not. We find that it has good empirical performance compared with naive method that neglects the selections. Detailed description of the Nextdoor analysis can be found in [1].</p>

<p>[1]Guan, Leying, and Robert Tibshirani. &ldquo;Post model-fitting exploration via a&rdquo; Next-Door&quot; analysis.&ldquo; arXiv preprint arXiv:1806.01326 (2018).</p>

<p><a id="install"></a></p>

<h2>Installation</h2>

<p>Like many other R packages, the simplest way to obtain <code>glmnet</code> is to install it directly from CRAN. Type the following command in R console:</p>

<pre><code class="r">install.packages(&quot;nextdoor&quot;, repos = &quot;https://cran.us.r-project.org&quot;)
</code></pre>

<p>Users may change the <code>repos</code> options depending on their locations and preferences. Other options such as the directories where to install the packages can be altered in the command. For more details, see <code>help(install.packages)</code>.</p>

<p>Here the R package has been downloaded and installed to the default directories.</p>

<p>The user can also install the package using source files in github by the following commands:</p>

<p>library(devtools)</p>

<p>install_github(&quot;LeyingGuan/NextDoor/nextdoor&rdquo;)</p>

<p><a id="glmnet"></a></p>

<h2>nextdoor.glmnet</h2>

<p>We cam apply the Next-door analysis to post-selection lasso regression model corresponds to the model minimizing the cross-validation error or applying the one-standard deviation rule using cv.glmnet. The function proximity.glmnet performs model training, model selection, unbiased error estimation and the test (p-value/model score) for cv.glmnet.</p>

<p>nextdoor.glmnet {nextdoor}  R Documentation
Perform training, model selection, unbiased error estimation and the proximity test(p-value/model score) for functions in glmnet
Description
Perform model selection, unbiased error estimation and the nextdoor test(p-value/model score) for functions in glmnet.</p>

<p>The two most important quantities nextdoor.glmnet produces are (1) p-value, which is the Bootstrap p-value using the debiased test error estimation without considering only the model selection, (2) model score, which is calculated as</p>

<p>\[model\; score = \frac{p\;value}{selection\;frequency}\]</p>

<p>for every feature we are interested in.</p>

<h3>Usage</h3>

<p>nextdoor.glmnet(x, y, cv_glm, nams = NULL, family = &ldquo;gaussian&rdquo;,  lossfun = NULL, standardize = T,
K = 100, B = 1000, alpha = 0.1, epsilon = 0.05<sup>2,</sup> epsilon2 =0.05<sup>2,</sup>
selectionType = 0, Bindex = NULL, pv = TRUE,  rescale = TRUE,
score = TRUE, B1 = 50, Bindex1 = NULL,trace = TRUE)</p>

<h4>Arguments</h4>

<ul>
<li><p><code>x</code>: n by p training feature matrix</p></li>
<li><p><code>y</code>: Length p response vector</p></li>
<li><p><code>nams</code>: a length p vector containing feature names. By default, nams = NULL, the features are named according to their column indexes in x.</p></li>
<li><p><code>cv_glm</code>: Return from the function cv.glmnet keep = T.</p></li>
<li><p><code>family</code>: Response type, it can be one of &ldquo;gaussian&rdquo;,&ldquo;binomial&rdquo;,&ldquo;poisson&rdquo;,&ldquo;multinomial&rdquo;. By default, family = &ldquo;gaussian&rdquo;. It should be consistent with cv_glm.</p></li>
<li><p>lossfun A user-specific loss function for model evaluation. If loss = NULL, by default, we will use the deviance.  </p></li>
<li><p><code>standardize</code>: Whether to standardize the data, standardize = T by default. It should be consistent with cv_glm.</p></li>
<li><p><code>K</code>: number of repetitions estimating the de-biased error.</p></li>
<li><p><code>B</code>: number of bootstrap repetitions estimating the p-value.</p></li>
<li><p>alpha: added errors&#39; level with added errors being covariance structure*alpha. By default, alpha = .1.</p></li>
<li><p><code>epsilon</code>: added errors&#39; level  with added errors being identity*min(covariance diagonal)*epsilon. By default, epsilon = 0.05<sup>2.</sup></p></li>
<li><p>epsilon2&#39;: added errors&#39; level in the Bootstrap with  added errors being min(covariance diagonal)*epsilon2. By default, epsilon2 = 0.05<sup>2</sup></p></li>
</ul>

<p>*<code>Bindex</code>: n by B index matrix for bootstrap. If Bindex == NULL, use the randomly generated bootstrap samples, otherwise, use the provide matrix.</p>

<p>*<code>selectionType</code>: if selectionType == 0, pick the model with the smallest randomized error, if selectionType == 1, use the 1se rule.</p>

<ul>
<li><code>pv</code>: if pv == True, estimate the p-values.</li>
</ul>

<p>*<code>rescale</code>: if rescale == True, perform the mean-rescaled Bootstrap.</p>

<ul>
<li><p><code>score</code>: if score == True, provide model scores.</p></li>
<li><p><code>B1</code>: number of repetitions for the paired Bootstrap used to create model score.</p></li>
<li><p><code>Bindex1</code>: n by B1 index matrix for paired bootstrap in the model score step. If Bindex1 == NULL, use the default Bootstrap, otherwise, use the provide matrix.</p></li>
</ul>

<p>*<code>trace</code>: if trace == True, print the p-values as they are calculated.</p>

<h4>Value</h4>

<ul>
<li><p><code>model0</code>: original model sequence</p></li>
<li><p><code>models</code>: list of proximal model sequences</p></li>
<li><p><code>errors0</code>: original error matrix</p></li>
<li><p><code>errors</code>: list of proximal model matrices</p></li>
<li><p><code>debiased_errors0</code>: de-biased estimate of the prediction error for the original process</p></li>
<li><p><code>debiased_errors</code>: de-biased estimates of the prediction error for the processes excluding a each of the selected feature</p></li>
<li><p><code>worsen</code>: estimated increase in prediction error</p></li>
<li><p><code>p_value</code>: p values for proximity analysis</p></li>
<li><p><code>selection_frequency</code>: frequency of features in S being selected</p></li>
<li><p><code>model_score</code>: model_score for proximity analysis</p></li>
<li><p><code>result_table</code>: organized result table</p></li>
</ul>

<h4>Examples</h4>

<p>data(prostateCancerData)</p>

<p>data_train = prostateCancerData$train</p>

<p>data_test = prostateCancerData$test</p>

<p>x = data_train$feature</p>

<p>y = data_train$response</p>

<p>nams = data_train$names</p>

<p>n=length(y)</p>

<p>set.seed(483)</p>

<p>R1 = proximity.glmnet(X = x, Y = y, family = &ldquo;gaussian&rdquo;, nfolds = 10,
                     nlambda = 30, standardize = F, alpha = .1,epsilon = 0.05<sup>2,</sup> epsilon2 = .05<sup>2,</sup>
                     B = 1000, B1 = 20)</p>

<p>print(round(R1$result_table,3))</p>

<p><a id="supervised1"></a></p>

<h2>getIndex</h2>

<p>The function getIndex chooses a model  based on randomized error curve. The users can use it to pick a model for any supervised learning algorithms they want to implement.</p>

<h3>Usage</h3>

<p>getIndex(errors0, alpha = 0.1, epsilon = 0.1, selectionType = 0,
  one_sds = rep(0, ncol(errors0)))</p>

<h3>Arguments</h3>

<ul>
<li><p><code>errors0</code>: the n by m errors of the original model sequence</p></li>
<li><p><code>alpha</code>: added error with covariance structure*alpha, by default, alpha = .1</p></li>
<li><p><code>epsilon</code>: added error with covariance structure being identity times min(covariance diagonal) times epsilon, by default, epsilon = 0.1</p></li>
<li><p><code>selectionType</code>: if selectionType == 0, pick the model with the smallest randomized error</p></li>
<li><p><code>one_sds</code>: if the selectionType is 1, the we choose the model with smallest index such that model error(randomized) &lt;= one_sds[i] + min error (randomized).</p></li>
</ul>

<h3>Value</h3>

<ul>
<li><code>model_index</code>: selected model index in the original model sequences based on the randomized error curve.</li>
</ul>

<p><a id="supervised2"></a></p>

<h2>nextdoor</h2>

<p>We can also apply the Nextdoor analysis to other supervised algorithms using the function proximity when the original model is picked using the function getIndex. It requires the user to have the prediction errors for the original model sequence and the errors for the next-door model sequences available.</p>

<h3>Usage</h3>

<p>nextdoor(errors0, errors, S, nams=NULL, K = 100, B = 1000, alpha = 0.1, epsilon = 0.05<sup>2,</sup> epsilon2 = 0.05<sup>2,Bindex</sup> = NULL,pv = TRUE,  rescale = TRUE, selectionType = 0, one_sds = rep(0, ncol(errors0)),trace = T)</p>

<h3>Arguments</h3>

<ul>
<li><p><code>errors0</code>: the n by m errors of the original model sequence</p></li>
<li><p><code>errors</code>: a list of n by m errors of the proximal model sequences</p></li>
<li><p><code>S</code>: a vector corresponding of names of the proximal sequences (name in errors)</p></li>
<li><p><code>nams</code>: a length p vector containing feature names. By default, nams = NULL, the features are named according to their column indexes in x.</p></li>
<li><p><code>K</code>: number of repetitions estimating the de-biased error</p></li>
<li><p><code>B</code>: number of bootstrap repetitions</p></li>
<li><p><code>alpha</code>: added error with covariance structure*alpha, by default, alpha = .1</p></li>
<li><p><code>epsilon</code>: added error with covariance structure being indentity times min(covariance diagonal) times epsilon, by default, epsilon =  0.05<sup>2.</sup></p></li>
<li><p><code>epsilon2</code>: added error in the Bootstrap step being min(covariance diagonal) times epsilon2, by default, epsilon2 = 0.05<sup>2</sup></p></li>
<li><p><code>Bindex</code>: n by B index matrix for bootstrap. if Bindex == NULL, use the default Bootstrap, otherwise, use the provide matrix.</p></li>
<li><p><code>pv</code>: if pv == True, estimate the p-values</p></li>
<li><p><code>rescale</code>: if rescale == True, perform the mean-rescaled Bootstrap</p></li>
<li><p><code>selectionType</code>: if selectionType == 0, pick the model with the smallest randomized error if selectionType == 1, use the 1se rule</p></li>
<li><p><code>one_sds</code>: if the selectionType is 1, the we choose the model with smallest index such that model error(randomized) &lt;= one_sds[i] + min error(randomized)</p></li>
<li><p><code>trace</code>: if trace == True, print the p-value process</p></li>
</ul>

<h3>Value</h3>

<ul>
<li><p><code>debiased_errors0</code>: de-biased estimate of the model error for the original procedure</p></li>
<li><p><code>debiased_errors</code>: de-biased estimate of the model error for the process excluding a specific feature</p></li>
<li><p><code>worsen</code>: estimated increase in prediction error</p></li>
<li><p><code>pv_value</code>: p values for proximity analysis</p></li>
</ul>

<h3>Example</h3>

<p>set.seed(48)
alphas = c(1:10)/10; 
errors0 = array(NA, dim = c(length(data$response),length(alphas))); errors=list()
for(i in 1:length(alphas)){
    model0 = ranger(response~., data = data, alpha = alphas[i])
    errors0[,i] = (data$response-model0$predictions)<sup>2</sup>
    for(j in 1:length(nams)){
       if(is.null(errors[j][[1]])){errors[[j]] = array(0, dim = c(length(data$response),length(alphas)))}
        data1 = data[,-j];model0 = ranger(response~., data = data1, alpha = alphas[i]) 
        errors[[j]][,i] = (data$response-model0$predictions)<sup>2</sup>
     }
 }
res = nextdoor(errors0 = errors0, errors = errors, S =c(1:length(nams)), nams=nams, B = 1000, alpha = 0.1, pv = TRUE,rescale = TRUE, selectionType = 0,trace = TRUE)</p>

</body>

</html>
